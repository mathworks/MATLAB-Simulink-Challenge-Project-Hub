Fill out this <strong>[form](https://www.mathworks.com/academia/student-challenge/mathworks-excellence-in-innovation-signup.html?tfa_1=Autonomous%20Vehicle%20localization&tfa_2=20)</strong> to **register** your intent to complete this project.

Fill out this <strong>[form](https://www.mathworks.com/academia/student-challenge/mathworks-excellence-in-innovation-submission-form.html?tfa_1=Autonomous%20Vehicle%20localization&tfa_2=20)</strong> to **submit** your solution to this project and qualify for the rewards.

<table>
<td><img src="https://gist.githubusercontent.com/robertogl/e0115dc303472a9cfd52bbbc8edb7665/raw/auto.png"  width=400 /></td>
<td><p><h1>Autonomous Vehicle Localization Using Onboard Sensors and HD Geolocated Maps</h1></p>
<p>Revolutionize the current transportation system by improving autonomous vehicles localization for level 5 automation.</p>
</table>

## Motivation

Autonomous vehicles are revolutionizing the way the current transportation system works and many companies are investing on this mega trend technology to secure a share in this market. Researchers and engineers are combining efforts to achieve a full driving automation (Level 5) system that is safe and comfortable for the passengers. Localization is a key component of an autonomous vehicle to enable autonomous driving by processing sensors data combined with high definition maps for accurate results.

## Project Description

Using a simulation platform from MathWorks Automated Driving Toolbox™ (ADT), either Driving Scenario or Unreal-based simulator, 
develop a demonstration integrating information from cameras, radar, Lidar, INS sensors as well as HERE HD map data to localize the vehicle 
with high precision. Use anything at your disposal in the Automated Driving Toolbox and Navigation Toolbox™.
The following features might be useful while building a prototype of a localization approach:
- Point cloud processing capabilities in the Computer Vision toolbox™ (CVT)
- Visual Simultaneous Localization and Mapping (SLAM), Structure from motion (SFM), Visual Odometry (VO) frameworks from the CVT
- Driving scenario generation capabilities in ADT
- Sensors from ADT: radar, camera, lidar
- Synthetic sensors from Navigation Toolbox: IMU, GPS, INS

The project as stated would have a very large scope and complexity. It would require that you add constraints to make it implementable in a realistic period of time.

Suggested high-level steps:

1. 	Build a simulation scenario with ego-vehicle and sensors using the Unreal Engine-based simulator in ADT. This simulation should be done in Simulink.

2. 	Use data from simulated lidar, INS, and camera sensors to design algorithms for accurate estimation of the car’s pose potentially using SLAM. Optionally, involve use of High-definition maps (from HERE) to further enhance your localization algorithms (https://www.mathworks.com/help/driving/ref/herehdlmreader.html).

3.	Compare your results against ground truth derived from Unreal simulator. 

## Background Material

- [Automated Driving Toolbox](https://www.mathworks.com/help/driving/)
- [Computer Vision Toolbox](https://www.mathworks.com/help/vision/)
- [Navigation Toolbox](https://www.mathworks.com/help/nav/)
- [Unreal Engine](https://www.unrealengine.com)
- [Unreal Engine Scenario Simulation](https://www.mathworks.com/help/driving/unreal-engine-scenario-simulation.html)

## Impact

Contribute to the change of automobile industry, and transportation system.

## Expertise Gained 

Autonomous Driving, Computer Vision, Robotics, SLAM, State Estimation, Sensor Fusion and Tracking

## Project Difficulty

Master’s level

## Project Discussion

[Dedicated discussion forum](https://github.com/mathworks/MathWorks-Excellence-in-Innovation/discussions/3) to ask/answer questions, comment, or share your ideas for solutions for this project.

## Proposed By

[thewitek](https://github.com/thewitek)

## Project Number

20

